{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"加载和预处理数据  文本.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMFcfeqO53kK0xbQkrcvvPw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"8Ew-DqBhGFEA","colab_type":"text"},"source":["#使用 tf.data 加载文本数据\n","\n","本教程为你提供了一个如何使用 tf.data.TextLineDataset 来加载文本文件的示例。TextLineDataset 通常被用来以文本文件构建数据集（原文件中的一行为一个样本) 。这适用于大多数的基于行的文本数据（例如，诗歌或错误日志) 。下面我们将使用相同作品（荷马的伊利亚特）三个不同版本的英文翻译，然后训练一个模型来通过单行文本确定译者。\n","\n","##环境搭建"]},{"cell_type":"code","metadata":{"id":"9z7V7SO7GsAa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":38},"outputId":"64171f5d-930b-4413-ddf2-08f3e582030b","executionInfo":{"status":"ok","timestamp":1579778182306,"user_tz":-480,"elapsed":9472,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["from __future__ import absolute_import,division,print_function,unicode_literals\n","\n","try:\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n","\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","import os"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 2.x selected.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gXRnz3nXHeYI","colab_type":"text"},"source":["三个版本的翻译分别来自于:\n","\n",". [William Cowper ](https://en.wikipedia.org/wiki/William_Cowper)— text\n","\n",". [Edward, Earl of Derby](https://en.wikipedia.org/wiki/Edward_Smith-Stanley,_14th_Earl_of_Derby) — text\n","\n",". [Samuel Butler]('https://en.wikipedia.org/wiki/Samuel_Butler_%28novelist%29 — text')\n","\n","本教程中使用的文本文件已经进行过一些典型的预处理，主要包括删除了文档页眉和页脚，行号，章节标题。请下载这些已经被局部改动过的文件。"]},{"cell_type":"code","metadata":{"id":"bTDUeKnHIaje","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":184},"outputId":"5e494546-68a2-431f-d816-992476487e2d","executionInfo":{"status":"ok","timestamp":1579778780804,"user_tz":-480,"elapsed":2134,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["DIRECTORY_URL = 'https://storage.googleapis.com/download.tensorflow.org/data/illiad/'\n","FILE_NAMES = ['cowper.txt', 'derby.txt', 'butler.txt']\n","\n","for name in FILE_NAMES:\n","  text_dir = tf.keras.utils.get_file(name,origin=DIRECTORY_URL+name)\n","\n","parent_dir = os.path.dirname(text_dir)\n","\n","parent_dir"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/illiad/cowper.txt\n","819200/815980 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/illiad/derby.txt\n","811008/809730 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/illiad/butler.txt\n","811008/807992 [==============================] - 0s 0us/step\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["'/root/.keras/datasets'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"0RNOU_1sJyXN","colab_type":"text"},"source":["###将文本加载到数据集中\n","迭代整个文件，将整个文件加载到自己的数据集中。\n","\n","每个样本都需要单独标记，所以请使用 tf.data.Dataset.map 来为每个样本设定标签。这将迭代数据集中的每一个样本并且返回（ example, label ）对。"]},{"cell_type":"code","metadata":{"id":"gww874z6KMO3","colab_type":"code","colab":{}},"source":["def labeler(example,index):\n","  return example,tf.cast(index,tf.int64)\n","\n","labeled_data_sets = []\n","\n","for i, file_name in enumerate(FILE_NAMES):\n","  lines_dataset = tf.data.TextLineDataset(os.path.join(parent_dir,file_name))\n","  labeled_dataset = lines_dataset.map(lambda ex:labeler(ex,i))\n","  labeled_data_sets.append(labeled_dataset)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BRWDGrtILcJR","colab_type":"text"},"source":["将这些标记的数据集合并到一个数据集中，然后对其进行随机化操作。"]},{"cell_type":"code","metadata":{"id":"PrN_57WxLqOt","colab_type":"code","colab":{}},"source":["BUFFER_SIZE = 50000\n","BATCH_SIZE = 64\n","TAKE_SIZE = 5000"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lGE5cItMLtuB","colab_type":"code","colab":{}},"source":["all_labeled_data = labeled_data_sets[0]\n","for labeled_dataset in labeled_data_sets[1:]:\n","  all_labeled_data = all_labeled_data.concatenate(labeled_dataset)\n","\n","all_labeled_data = all_labeled_data.shuffle(\n","    BUFFER_SIZE,reshuffle_each_iteration=False\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c4uZSztYMfP_","colab_type":"text"},"source":["你可以使用 tf.data.Dataset.take 与 print 来查看 (example, label) 对的外观。numpy 属性显示每个 Tensor 的值。"]},{"cell_type":"code","metadata":{"id":"x4wSz6FMNK-h","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":142},"outputId":"d572ecd7-9735-44d7-cb5e-f936f75de8f1","executionInfo":{"status":"ok","timestamp":1579779693055,"user_tz":-480,"elapsed":2073,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["for ex in all_labeled_data.take(5):\n","  print(ex)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["(<tf.Tensor: shape=(), dtype=string, numpy=b'Upon the lofty heights of Pedasus.'>, <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n","(<tf.Tensor: shape=(), dtype=string, numpy=b'At once he came where noble Hector stood'>, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n","(<tf.Tensor: shape=(), dtype=string, numpy=b'Both foot and horse; and loud the tumult rose.'>, <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n","(<tf.Tensor: shape=(), dtype=string, numpy=b'On this Ulysses went at once into his tent, put his shield about his'>, <tf.Tensor: shape=(), dtype=int64, numpy=2>)\n","(<tf.Tensor: shape=(), dtype=string, numpy=b'The son of OEnops; and Oresbius, girt'>, <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wh0Lycs6NRFq","colab_type":"text"},"source":["##将文本编码成数字\n","机器学习基于的是数字而非文本，所以字符串需要被转化成数字列表。 为了达到此目的，我们需要构建文本与整数的一一映射。\n","\n","###建立词汇表\n","首先，通过将文本标记为单独的单词集合来构建词汇表。在 TensorFlow 和 Python 中均有很多方法来达成这一目的。在本教程中:\n","\n","1. 迭代每个样本的 numpy 值。\n","2. 使用 tfds.features.text.Tokenizer 来将其分割成 token。\n","3. 将这些 token 放入一个 Python 集合中，借此来清除重复项。\n","4. 获取该词汇表的大小以便于以后使用。"]},{"cell_type":"code","metadata":{"id":"wqYFzVu1NqSl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":38},"outputId":"f28bc91b-a829-424c-f9b3-dbace5ac996e","executionInfo":{"status":"ok","timestamp":1579779961276,"user_tz":-480,"elapsed":6123,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["tokenizer = tfds.features.text.Tokenizer()\n","\n","vocabulary_set = set()\n","for text_tensor,_ in all_labeled_data:\n","  some_tokens = tokenizer.tokenize(text_tensor.numpy())\n","  vocabulary_set.update(some_tokens)\n","\n","vocab_size = len(vocabulary_set)\n","vocab_size"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["17178"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"06BhT7U3ORlV","colab_type":"text"},"source":["###样本编码\n","通过传递 vocabulary_set 到 tfds.features.text.TokenTextEncoder 来构建一个编码器。编码器的 encode 方法传入一行文本，返回一个整数列表。"]},{"cell_type":"code","metadata":{"id":"fjpedX08Qaqk","colab_type":"code","colab":{}},"source":["encoder = tfds.features.text.TokenTextEncoder(vocabulary_set)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aEwYXli7QnzI","colab_type":"text"},"source":["你可以尝试运行这一行代码并查看输出的样式。"]},{"cell_type":"code","metadata":{"id":"4uJv-bO_QrTi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":38},"outputId":"947701be-edf6-4422-d8db-3f28863ce3a8","executionInfo":{"status":"ok","timestamp":1579780619682,"user_tz":-480,"elapsed":1485,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["example_text = next(iter(all_labeled_data))[0].numpy()\n","print(example_text)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["b'Upon the lofty heights of Pedasus.'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pcOVVpHXQzeU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":38},"outputId":"68989a0f-1a0e-4fce-a499-5d19d07d2704","executionInfo":{"status":"ok","timestamp":1579780776571,"user_tz":-480,"elapsed":1050,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["encoded_example = encoder.encode(example_text)\n","print(encoded_example)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["[13288, 11959, 1512, 15247, 12410, 2424]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Znxq2ZVaQ7cF","colab_type":"text"},"source":["现在，在数据集上运行编码器（通过将编码器打包到 tf.py_function 并且传参至数据集的 map 方法的方式来运行）。"]},{"cell_type":"code","metadata":{"id":"IQpM5M-VRgy_","colab_type":"code","colab":{}},"source":["def encode(text_tensor, label):\n","  encoded_text = encoder.encode(text_tensor.numpy())\n","  return encoded_text, label\n","\n","def encode_map_fn(text, label):\n","  # py_func doesn't set the shape of the returned tensors.\n","  encoded_text, label = tf.py_function(encode, \n","                                       inp=[text, label], \n","                                       Tout=(tf.int64, tf.int64))\n","\n","  # `tf.data.Datasets` work best if all components have a shape set\n","  #  so set the shapes manually: \n","  encoded_text.set_shape([None])\n","  label.set_shape([])\n","\n","  return encoded_text, label\n","\n","\n","all_encoded_data = all_labeled_data.map(encode_map_fn)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6NPO5eFJS5kZ","colab_type":"text"},"source":["###将数据集分割为测试集和训练集且进行分支\n","使用 tf.data.Dataset.take 和 tf.data.Dataset.skip 来建立一个小一些的测试数据集和稍大一些的训练数据集。\n","\n","在数据集被传入模型之前，数据集需要被分批。最典型的是，每个分支中的样本大小与格式需要一致。但是数据集中样本并不全是相同大小的（每行文本字数并不相同）。因此，使用 tf.data.Dataset.padded_batch（而不是 batch ）将样本填充到相同的大小。"]},{"cell_type":"code","metadata":{"id":"KQymz-UnTBG-","colab_type":"code","colab":{}},"source":["train_data = all_encoded_data.skip(TAKE_SIZE).shuffle(BUFFER_SIZE)\n","train_data = train_data.padded_batch(BATCH_SIZE,tf.compat.v1.data.get_output_shapes(train_data))\n","\n","test_data = all_encoded_data.take(TAKE_SIZE)\n","test_data = test_data.padded_batch(BATCH_SIZE,tf.compat.v1.data.get_output_shapes(test_data))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"659_-p-QUFcD","colab_type":"text"},"source":["现在，test_data 和 train_data 不是（ example, label ）对的集合，而是批次的集合。每个批次都是一对（多样本, 多标签 ），表示为数组。"]},{"cell_type":"code","metadata":{"id":"DyW33xSLX5KT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"outputId":"0035c43d-20db-416d-9040-8cd7b7adc92d","executionInfo":{"status":"ok","timestamp":1579782537889,"user_tz":-480,"elapsed":8483,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["sample_text,sample_labels = next(iter(test_data))\n","sample_text[0],sample_labels[0]"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<tf.Tensor: shape=(16,), dtype=int64, numpy=\n"," array([13288, 11959,  1512, 15247, 12410,  2424,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0])>,\n"," <tf.Tensor: shape=(), dtype=int64, numpy=1>)"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"yf5TLoX4YGEq","colab_type":"text"},"source":["由于我们引入了一个新的 token 来编码（填充零），因此词汇表大小增加了一个。"]},{"cell_type":"code","metadata":{"id":"ZJSeB39aYPw1","colab_type":"code","colab":{}},"source":["vocab_size +=1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9XPDoPR9YSzM","colab_type":"text"},"source":["##建立模型"]},{"cell_type":"code","metadata":{"id":"W5yesihEYW0R","colab_type":"code","colab":{}},"source":["model = tf.keras.Sequential()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3zV863O3Yapb","colab_type":"text"},"source":["第一层将整数表示转换为密集矢量嵌入。更多内容请查阅 [Word Embeddings](https://www.tensorflow.org/tutorials/sequences/word_embeddings) 教程。"]},{"cell_type":"code","metadata":{"id":"dd4MFV8iYix-","colab_type":"code","colab":{}},"source":["model.add(tf.keras.layers.Embedding(vocab_size,64))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yy7-tWDmYquw","colab_type":"text"},"source":["下一层是 LSTM 层，它允许模型利用上下文中理解单词含义。 LSTM 上的双向包装器有助于模型理解当前数据点与其之前和之后的数据点的关系。"]},{"cell_type":"code","metadata":{"id":"WQjUZdt-YunI","colab_type":"code","colab":{}},"source":["model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m28E27CrY7Xz","colab_type":"text"},"source":["最后，我们将获得一个或多个紧密连接的层，其中最后一层是输出层。输出层输出样本属于各个标签的概率，最后具有最高概率的分类标签即为最终预测结果。"]},{"cell_type":"code","metadata":{"id":"ynJ4wnXrZCiL","colab_type":"code","colab":{}},"source":["#一个或多个紧密连接的层\n","#编辑`for`行的列表去检测层的大小\n","for units in [64,64]:\n","  model.add(tf.keras.layers.Dense(units,activation='relu'))\n","\n","#输出层 第一个参数是标签个数\n","model.add(tf.keras.layers.Dense(3,activation='softmax'))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dIC1rUTVctwN","colab_type":"text"},"source":["最后，编译这个模型。对于一个 softmax 分类模型来说，通常使用 sparse_categorical_crossentropy 作为其损失函数。你可以尝试其他的优化器，但是 adam 是最常用的。"]},{"cell_type":"code","metadata":{"id":"BDgD747pc8F_","colab_type":"code","colab":{}},"source":["model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aBTQFKk7dK28","colab_type":"text"},"source":["###训练模型\n","利用提供的数据训练出的模型有着不错的精度（大约 83% ）。\n"]},{"cell_type":"code","metadata":{"id":"-ivNb9S_dQPt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":184},"outputId":"46fb9549-5b16-4ea0-de69-77b8ac645653","executionInfo":{"status":"ok","timestamp":1579783990358,"user_tz":-480,"elapsed":83419,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["model.fit(train_data,epochs=3,validation_data=test_data)"],"execution_count":36,"outputs":[{"output_type":"stream","text":["Epoch 1/3\n","697/697 [==============================] - 34s 49ms/step - loss: 0.5171 - accuracy: 0.7463 - val_loss: 0.3810 - val_accuracy: 0.8372\n","Epoch 2/3\n","697/697 [==============================] - 24s 35ms/step - loss: 0.2965 - accuracy: 0.8686 - val_loss: 0.3647 - val_accuracy: 0.8402\n","Epoch 3/3\n","697/697 [==============================] - 24s 35ms/step - loss: 0.2254 - accuracy: 0.9023 - val_loss: 0.3879 - val_accuracy: 0.8404\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fd25a387390>"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"mZtR2AobdWWW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":59},"outputId":"88c6ecaf-4d21-4c06-d561-0ab00994a06c","executionInfo":{"status":"ok","timestamp":1579784060174,"user_tz":-480,"elapsed":3476,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["eval_loss,eval_acc = model.evaluate(test_data)\n","print('\\nEval loss: {}, Eval accuracy: {}'.format(eval_loss,eval_acc))"],"execution_count":37,"outputs":[{"output_type":"stream","text":["     79/Unknown - 3s 34ms/step - loss: 0.3879 - accuracy: 0.8404\n","Eval loss: 0.38792922659010826, Eval accuracy: 0.840399980545044\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QzhmM-WUd68p","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}