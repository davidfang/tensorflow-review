{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"加载和预处理数据 TF.Text.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPZynpbksiuJZlaAkDyvQk8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"977vzbJWilYq","colab_type":"text"},"source":["##介绍\n","TensorFlow Text提供了可与TensorFlow 2.0一起使用的与文本相关的类和操作的集合。该库可以执行基于文本的模型所需的常规预处理，并包括其他对核心TensorFlow不提供的对序列建模有用的功能。\n","\n","在文本预处理中使用这些操作的好处是它们在TensorFlow图中完成。您无需担心训练中的标记化与推理时的标记化或管理预处理脚本不同。\n","\n","##渴望执行\n","TensorFlow Text需要TensorFlow 2.0，并且与eager模式和graph模式完全兼容。"]},{"cell_type":"code","metadata":{"id":"Au4-0AEWjbiU","colab_type":"code","colab":{}},"source":["!pip install -q tensorflow-text"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"33tG7D1VjAES","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":38},"outputId":"57b5762d-a273-402b-fd63-ea53e6ce7976","executionInfo":{"status":"ok","timestamp":1579836099205,"user_tz":-480,"elapsed":8776,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["try:\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n","\n","import tensorflow as tf\n","import tensorflow_text as text"],"execution_count":3,"outputs":[{"output_type":"stream","text":["TensorFlow 2.x selected.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1it5_LMAkd5O","colab_type":"text"},"source":["###统一码\n","大多数操作人员期望字符串使用UTF-8。如果您使用其他编码，则可以使用核心tensorflow转码op将代码转码为UTF-8。如果您的输入可能无效，您也可以使用相同的操作将字符串强制为结构上有效的UTF-8。"]},{"cell_type":"code","metadata":{"id":"S48BOe0QksMQ","colab_type":"code","colab":{}},"source":["docs = tf.constant([u'Everything not saved will be lost.'.encode('UTF-16-BE'),u'Sad☹'.encode('UTF-16-BE')])\n","utf8_docs = tf.strings.unicode_transcode(docs,input_encoding='UTF-16-BE',output_encoding='UTF-8')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ijL_197XldbN","colab_type":"text"},"source":["##代币化\n","令牌化是将字符串分解为令牌的过程。通常，这些标记是单词，数字和/或标点符号。\n","\n","主要接口分别是Tokenizer和TokenizerWithOffsets，tokenize并且tokenize_with_offsets分别具有单一方法。现在有多个令牌生成器。这些工具TokenizerWithOffsets（扩展了Tokenizer）中的每个工具都包括用于将字节偏移量获取到原始字符串中的选项。这使调用者可以知道创建令牌的原始字符串中的字节。\n","\n","所有令牌生成器都返回RaggedTensors，其令牌的最内层维度映射到原始单个字符串。结果，所得形状的等级增加了一个。如果您不熟悉它们，请查看参差不齐的张量指南。https://www.tensorflow.org/guide/ragged_tensors\n","\n","##空白令牌生成器\n","这是一个基本的令牌生成器，用于在ICU定义的空白字符（例如，空格，制表符，换行）上分割UTF-8字符串。"]},{"cell_type":"code","metadata":{"id":"3T45ntbQlpjT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"outputId":"0b35d899-6ff3-4046-8ada-972023e6c013","executionInfo":{"status":"ok","timestamp":1579836597378,"user_tz":-480,"elapsed":7631,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["tokenizer = text.WhitespaceTokenizer()\n","tokens = tokenizer.tokenize(['everything not saved will be lost.',u'Sad☹'.encode('UTF-8')])\n","print(tokens.to_list())"],"execution_count":5,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-2.1.0/python3.6/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n","Instructions for updating:\n","`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n","[[b'everything', b'not', b'saved', b'will', b'be', b'lost.'], [b'Sad\\xe2\\x98\\xb9']]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"X3Pgr4p4mUY-","colab_type":"text"},"source":["###UnicodeScriptTokenizer\n","该令牌生成器根据Unicode脚本边界拆分UTF-8字符串。使用的脚本代码与Unicode（ICU）UScriptCode值的国际组件相对应。请参阅：http://icu-project.org/apiref/icu4c/uscript_8h.html\n","\n","实际上，这与相似，WhitespaceTokenizer最明显的区别是它将标点符号（USCRIPT_COMMON）与语言文本（例如USCRIPT_LATIN，USCRIPT_CYRILLIC等）分开，同时也将语言文本彼此分开。"]},{"cell_type":"code","metadata":{"id":"w43kT-4imeWu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":58},"outputId":"93d16361-a2af-4b3d-a54c-f949c985205b","executionInfo":{"status":"ok","timestamp":1579836736524,"user_tz":-480,"elapsed":666,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["tokenizer = text.UnicodeScriptTokenizer()\n","tokens = tokenizer.tokenize(['everything not saved will be lost.',u'Sad☹'.encode('UTF-8')])\n","print(tokens.to_list())"],"execution_count":6,"outputs":[{"output_type":"stream","text":["[[b'everything', b'not', b'saved', b'will', b'be', b'lost', b'.'], [b'Sad', b'\\xe2\\x98\\xb9']]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ABQHZLw7m4Eh","colab_type":"text"},"source":["###Unicode拆分\n","当对没有空格的语言进行标记化以分割单词时，通常仅按字符进行拆分，这可以使用内核中找到的unicode_split op 来完成。"]},{"cell_type":"code","metadata":{"id":"CJ3vRcLYm9CS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":58},"outputId":"2d667b87-8826-49e3-ddd7-352f508e8c2b","executionInfo":{"status":"ok","timestamp":1579836849465,"user_tz":-480,"elapsed":684,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["tokens = tf.strings.unicode_split([u'仅今年前'.encode('UTF-8')],'UTF-8')\n","print(tokens.to_list())"],"execution_count":8,"outputs":[{"output_type":"stream","text":["[[b'\\xe4\\xbb\\x85', b'\\xe4\\xbb\\x8a', b'\\xe5\\xb9\\xb4', b'\\xe5\\x89\\x8d']]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ukujggJ7nRIp","colab_type":"text"},"source":["###偏移量\n","在对字符串进行标记时，通常需要知道标记在原始字符串中的何处。因此，每个实现TokenizerWithOffsets的令牌生成器都有一个tokenize_with_offsets方法，该方法将返回字节偏移量和令牌。offset_starts列出每个令牌开始的原始字符串中的字节，而offset_limits列出每个令牌结束的字节。"]},{"cell_type":"code","metadata":{"id":"dXRZyz24nYvs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":100},"outputId":"2557e79e-8ed3-4d12-aa61-d20cc7e42d25","executionInfo":{"status":"ok","timestamp":1579837040316,"user_tz":-480,"elapsed":686,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["tokenizer = text.UnicodeScriptTokenizer()\n","(tokens,offset_starts,offset_limits) = tokenizer.tokenize_with_offsets(['everything not saved will be lost.',u'Sad☹'.encode('UTF-8')])\n","print(tokens.to_list())\n","print(offset_starts.to_list())\n","print(offset_limits.to_list())"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[[b'everything', b'not', b'saved', b'will', b'be', b'lost', b'.'], [b'Sad', b'\\xe2\\x98\\xb9']]\n","[[0, 11, 15, 21, 26, 29, 33], [0, 3]]\n","[[10, 14, 20, 25, 28, 33, 34], [3, 6]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"e0pGBqESoCOQ","colab_type":"text"},"source":["###TF.Data示例\n","标记程序可以与tf.data API一起正常工作。下面提供了一个简单的示例。"]},{"cell_type":"code","metadata":{"id":"lz_B5lAnoKw8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":59},"outputId":"36821f3c-cf96-45ec-a79f-6b755f04a3e1","executionInfo":{"status":"ok","timestamp":1579837387019,"user_tz":-480,"elapsed":2150,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["docs = tf.data.Dataset.from_tensor_slices([['Never tell me the odds.'],[\"It's a trap!\"]])\n","tokenizer = text.WhitespaceTokenizer()\n","tokenized_docs = docs.map(lambda x:tokenizer.tokenize(x))\n","iterator = iter(tokenized_docs)\n","print(next(iterator).to_list())\n","print(next(iterator).to_list())"],"execution_count":10,"outputs":[{"output_type":"stream","text":["[[b'Never', b'tell', b'me', b'the', b'odds.']]\n","[[b\"It's\", b'a', b'trap!']]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"INTm8RHnpWgy","colab_type":"text"},"source":["###其他文字操作\n","TF.Text打包了其他有用的预处理操作。我们将在下面复习一些。\n","\n","###字形\n","一些自然语言理解模型中使用的一个共同特征是查看文本字符串是否具有特定属性。例如，断句模型可能包含检查单词大写或标点字符是否在字符串末尾的功能。\n","\n","Wordshape定义了各种有用的基于正则表达式的帮助器函数，用于匹配输入文本中的各种相关模式。这里有一些例子。"]},{"cell_type":"code","metadata":{"id":"Yx49js4dplUg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":101},"outputId":"f8d95449-e99b-4ebc-c1d4-1648388ff522","executionInfo":{"status":"ok","timestamp":1579837851500,"user_tz":-480,"elapsed":677,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["tokenizer = text.WhitespaceTokenizer()\n","tokens = tokenizer.tokenize(['Everything not saved will be lost.',u'Sad☹'.encode('UTF-8')])\n","\n","f1 = text.wordshape(tokens,text.WordShape.HAS_TITLE_CASE)\n","f2 = text.wordshape(tokens,text.WordShape.IS_UPPERCASE)\n","f3 = text.wordshape(tokens,text.WordShape.HAS_SOME_PUNCT_OR_SYMBOL)\n","f4 = text.wordshape(tokens,text.WordShape.IS_NUMERIC_VALUE)\n","\n","print(f1.to_list())\n","print(f2.to_list())\n","print(f3.to_list())\n","print(f4.to_list())"],"execution_count":12,"outputs":[{"output_type":"stream","text":["[[True, False, False, False, False, False], [True]]\n","[[False, False, False, False, False, False], [False]]\n","[[False, False, False, False, False, True], [True]]\n","[[False, False, False, False, False, False], [False]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nodwWh9kq9M4","colab_type":"text"},"source":["###N克和滑动窗口\n","N-gram是给定滑动窗口大小n的连续单词。组合令牌时，支持三种还原机制。对于文本，您可能想使用Reduction.STRING_JOIN将字符串彼此附加的字符串。默认的分隔符是空格，但是可以使用string_separater参数更改。\n","\n","其他两种归约方法最常用于数值，它们是Reduction.SUM和Reduction.MEAN。"]},{"cell_type":"code","metadata":{"id":"Ae2D9ZSnrQJL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":58},"outputId":"b7784f98-a613-4ec7-a3dd-4060b7a2759f","executionInfo":{"status":"ok","timestamp":1579838039723,"user_tz":-480,"elapsed":697,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["tokenizer = text.WhitespaceTokenizer()\n","tokens = tokenizer.tokenize(['Everything not saved will be lost',u'Sad☹'.encode('UTF-8')])\n","\n","bigrams = text.ngrams(tokens,2,reduction_type=text.Reduction.STRING_JOIN)\n","\n","print(bigrams.to_list())"],"execution_count":13,"outputs":[{"output_type":"stream","text":["[[b'Everything not', b'not saved', b'saved will', b'will be', b'be lost'], []]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o63Hz0uIr2OH","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}